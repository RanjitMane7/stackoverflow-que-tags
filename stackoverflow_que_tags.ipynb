{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stackoverflow-que-tags",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTAV0YnxjEKGyvjcm+M+Av",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RanjitMane7/stackoverflow-que-tags/blob/main/stackoverflow_que_tags.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY1ya6do8jeZ"
      },
      "source": [
        "tags_list = ['tensorflow', 'keras', 'pandas', 'scikit-learn', 'seaborn', 'numpy', 'matplotlib']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJhSUoWFokFb"
      },
      "source": [
        "#data_url = r'gdrive://home/bq-results-20210506-000204-wrn723q78ynd/bq-results-20210506-000204-wrn723q78ynd.csv'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW3hOKZT0JBX"
      },
      "source": [
        "#!gsutil cp 'gdrive://home/bq-results-20210506-000204-wrn723q78ynd/bq-results-20210506-000204-wrn723q78ynd.csv' ./"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSr69vsff1IX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S29iWCKU49Kx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRbTmSQCgDkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b9dc58-3dbc-40f9-e5c8-2c09e68cb54b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBLCGOZN5cio"
      },
      "source": [
        "df = pd.read_csv(\"/gdrive/MyDrive/bq-results-20210506-000204-wrn723q78ynd/bq-results-20210506-000204-wrn723q78ynd.csv\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QMIRtBAv-M1a",
        "outputId": "996bab4b-adff-4ea9-c73c-33f8f7912c50"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blabla: scatter and colorbar values i have dat...</td>\n",
              "      <td>python,matplotlib</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>code is working but with a 'deprecationwarning...</td>\n",
              "      <td>python,csv,numpy,statistics,scipy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>design strategy for managing and processing da...</td>\n",
              "      <td>dataset,pandas,pytables</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>python pattern's restrictingwrapper with metac...</td>\n",
              "      <td>python,design-patterns,numpy,pandas,metaclass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>blabla axes formatting i am creating a realtim...</td>\n",
              "      <td>python,matplotlib,pyqt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                           tags\n",
              "0  blabla: scatter and colorbar values i have dat...                              python,matplotlib\n",
              "1  code is working but with a 'deprecationwarning...              python,csv,numpy,statistics,scipy\n",
              "2  design strategy for managing and processing da...                        dataset,pandas,pytables\n",
              "3  python pattern's restrictingwrapper with metac...  python,design-patterns,numpy,pandas,metaclass\n",
              "4  blabla axes formatting i am creating a realtim...                         python,matplotlib,pyqt"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DJL3JRJu_Ed"
      },
      "source": [
        "def req_tags(tags):\n",
        "    tags_short=[]\n",
        "    for i in tags_list:\n",
        "        if i in tags:\n",
        "            tags_short.append(i)\n",
        "    return ','.join(tags_short)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p2K4tTVwbeQ"
      },
      "source": [
        "df['tags'] = df['tags'].apply(req_tags)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4uyI36ix1fK"
      },
      "source": [
        "#df['tags'][:5].apply(for t)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "P3SoigeHtoiT",
        "outputId": "f129d0a4-243c-4454-c980-7b4b1dc33c1a"
      },
      "source": [
        "# aa = df['tags'][:1]\n",
        "# aa.apply(req_tags)\n",
        "df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blabla: scatter and colorbar values i have dat...</td>\n",
              "      <td>matplotlib</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>code is working but with a 'deprecationwarning...</td>\n",
              "      <td>numpy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>design strategy for managing and processing da...</td>\n",
              "      <td>pandas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>python pattern's restrictingwrapper with metac...</td>\n",
              "      <td>pandas,numpy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>blabla axes formatting i am creating a realtim...</td>\n",
              "      <td>matplotlib</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text          tags\n",
              "0  blabla: scatter and colorbar values i have dat...    matplotlib\n",
              "1  code is working but with a 'deprecationwarning...         numpy\n",
              "2  design strategy for managing and processing da...        pandas\n",
              "3  python pattern's restrictingwrapper with metac...  pandas,numpy\n",
              "4  blabla axes formatting i am creating a realtim...    matplotlib"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_yNlMeCn-dm",
        "outputId": "33cde630-9f4a-4f43-ca31-0eaa03ae6c63"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 411626 entries, 0 to 411625\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    411626 non-null  object\n",
            " 1   tags    411626 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 6.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72fnLD7LoCbd",
        "outputId": "9aa01223-0dba-45e2-a698-694c09bdc471"
      },
      "source": [
        "df['tags'].describe()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     411626\n",
              "unique        64\n",
              "top       pandas\n",
              "freq      167334\n",
              "Name: tags, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v8JAcN2qIjL",
        "outputId": "866e10ce-e614-4ab0-d5af-b53422e80b20"
      },
      "source": [
        "df['tags'].values[:10]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['matplotlib', 'numpy', 'pandas', 'pandas,numpy', 'matplotlib',\n",
              "       'numpy,matplotlib', 'numpy', 'numpy', 'matplotlib', 'numpy'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alT1TAkFoMqV",
        "outputId": "776a9e2a-3d13-47b4-8a8e-45643f24727a"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(411626, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKXqFg8O-SAx"
      },
      "source": [
        "#imports\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImIAoV-x-2NM"
      },
      "source": [
        "#Shuffling the data\n",
        "#df = shuffle(df, n_samples=100000, random_state=101)\n",
        "df = shuffle(df, random_state=101)\n",
        "# df.shape\n",
        "# df.head()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68GDBhAJhgf5",
        "outputId": "b745a8b1-278c-4179-8cb5-f572e6a74eed"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(411626, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAksVu-hfOUA",
        "outputId": "317cfea7-0d8e-4c79-c9d5-d0544c9810d8"
      },
      "source": [
        "##Encode tags to multi-hot\n",
        "\n",
        "tags_split = [tags.split(',') for tags in df['tags'].values]\n",
        "print(len(tags_split), '\\n')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "411626 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WCNLHTwioRC",
        "outputId": "ea0e6df4-9263-4447-e32c-fb8d5a07c736"
      },
      "source": [
        "tag_encoder = MultiLabelBinarizer()\n",
        "tags_encoded = tag_encoder.fit_transform(tags_split)\n",
        "num_tags = len(tags_encoded[0])\n",
        "\n",
        "print(df['text'].values[0])\n",
        "print(tag_encoder.classes_)\n",
        "print(tags_encoded[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gridsearchcv: internal logic i'm trying to understand how gridsearchcv's logic works. i looked at here, the official documentation, and the source code, but i couldn't figure out the following:\n",
            "\n",
            "what is the general logic behind gridsearchcv?\n",
            "\n",
            "clarifications:\n",
            "\n",
            "if i use the default cv = 5, what are the % splits of the input data\n",
            "into: train, validation, and test?\n",
            "how often does gridsearchcv perform such a split, and how does it decide which observation belong to train / validation / test?\n",
            "since cross validation is being done, where does any averaging come into play for the hyper parameter tuning? i.e. is the optimal hyper parameter value is one that optimizes some sort of average?\n",
            "\n",
            "this question here shares my concern, but i don't know how up-to-date the information is and i am not sure i understand all the information there. for example, according to the op, my understanding is that:\n",
            "\n",
            "the test set is 25% of the input data set and is created once.\n",
            "the union  of the train set and validation set is correspondingly created once and this union is 75% of the original data.\n",
            "then, the procedure creates 5 (because cv = 5) further splits of this 75% into 60% train and 15% validation\n",
            "the optimized hyper parameter value is one that optimizes the average of some metric over these 5 splits.\n",
            "\n",
            "is this understanding correct and still applicable now? and how does the procedure do the original 25%-75% split?\n",
            "['keras' 'matplotlib' 'numpy' 'pandas' 'scikit-learn' 'seaborn'\n",
            " 'tensorflow']\n",
            "[0 0 0 0 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyGpGWFEtTfB",
        "outputId": "ca79f2d4-2f38-4a10-acde-74a8c7b5fe0b"
      },
      "source": [
        "print(tag_encoder.classes_)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['keras' 'matplotlib' 'numpy' 'pandas' 'scikit-learn' 'seaborn'\n",
            " 'tensorflow']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS1n3VocpWpi",
        "outputId": "86bb6c85-32e3-408c-d33c-116e0df59ab0"
      },
      "source": [
        "print(len(tags_encoded))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "411626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUtfXXIqzZL3",
        "outputId": "560331f2-adda-4657-a164-117a9c08ae7d"
      },
      "source": [
        "#train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_size = int(len(df) * .8)\n",
        "print(\"Train size: %d\" % train_size)\n",
        "print(\"Test size: %d\" % (len(df) - train_size))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 329300\n",
            "Test size: 82326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X07u3zS0Ewb"
      },
      "source": [
        "#spliting data between train and test\n",
        "train_tags = tags_encoded[:train_size]\n",
        "test_tags = tags_encoded[train_size:]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSVydgtDyaYl"
      },
      "source": [
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8j1ptFL_CDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ebe735a-5e2a-453b-a05f-63b90264b439"
      },
      "source": [
        "%%writefile preprocess.py\n",
        "\n",
        "from tensorflow.keras.preprocessing import text\n",
        "\n",
        "class TextPreprocessor(object):\n",
        "    def __init__(self, vocab_size):\n",
        "        self._vocab_size = vocab_size\n",
        "        self._tokenizer = None\n",
        "\n",
        "    def create_tokenizer(self, text_list):\n",
        "        tokenizer = text.Tokenizer(num_words=self._vocab_size)\n",
        "        tokenizer.fit_on_texts(text_list)\n",
        "        self._tokenizer = tokenizer\n",
        "\n",
        "    def transform_text(self, text_list):\n",
        "        text_matrix = self._tokenizer.texts_to_matrix(text_list)\n",
        "        return text_matrix"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing preprocess.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1ulTv_mKl4V"
      },
      "source": [
        "## Create bag of words matrices\n",
        "\n",
        "from preprocess import TextPreprocessor\n",
        "\n",
        "train_qs = df['text'].values[:train_size]\n",
        "test_qs = df['text'].values[train_size:]\n",
        "\n",
        "VOCAB_SIZE = 400\n",
        "\n",
        "processor = TextPreprocessor(VOCAB_SIZE)\n",
        "processor.create_tokenizer(train_qs)\n",
        "\n",
        "body_train = processor.transform_text(train_qs)\n",
        "body_test = processor.transform_text(test_qs)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZd0UUlj3Cf3",
        "outputId": "f5f98489-220d-44f3-b6b8-20d121315e10"
      },
      "source": [
        "#preview of training data\n",
        "print(len(body_train[0]))\n",
        "print(body_train[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400\n",
            "[0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA77j2xX4VXz",
        "outputId": "04aff332-1b7a-4ffd-b810-765985f32c95"
      },
      "source": [
        "print(df['text'][0])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "blabla: scatter and colorbar values i have data:\n",
            "\n",
            "values = np.array( [0,1,2,3,4,5] )\n",
            "\n",
            "\n",
            "i want to plot values as pyplot.scatter with different sizes and colours. also, i want to resize the dots so the smallest dots are well visible.\n",
            "\n",
            "if i do:\n",
            "\n",
            "sc = pyplot.scatter ( pos_x, pos_y, values )\n",
            "pyplot.colorbar( sc )\n",
            "\n",
            "\n",
            "then i get the proper values and colors, but the smallest dots are too small. now if i do:\n",
            "\n",
            "values_scaled = (values * 2 + 1)\n",
            "sc = pyplot.scatter ( pos_x, pos_y, values_scaled )\n",
            "pyplot.colorbar( sc )\n",
            "\n",
            "\n",
            "then the dots have acceptable sizes (although a bit fake) but the colorbar legend starts at 1 and ends at 11, which i don't want. i want to scale just sizes of the dots, but not the values assigned there. how to do that?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE5Y6PS64eHf"
      },
      "source": [
        "**Build and Train our Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKngkH8L4Vxy"
      },
      "source": [
        "#Save the tokenizer state\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('./processor_state.pkl', 'wb') as f:\n",
        "    pickle.dump(processor, f)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV3YFYeJ7ggv",
        "outputId": "9908df45-6670-4729-f76c-54d1106f85c6"
      },
      "source": [
        "num_tags"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHqCnfZQ5gIq",
        "outputId": "aef93ac8-230b-45da-9b30-f3d5fe71dc94"
      },
      "source": [
        "## Create the model\n",
        "\n",
        "def create_model(vocab_size, num_tags):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(50, input_shape=(vocab_size,), activation='relu'))\n",
        "    model.add(Dense(25, activation='relu'))\n",
        "    model.add(Dense(num_tags, activation='sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer='adam',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = create_model(VOCAB_SIZE, num_tags)\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 50)                20050     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 182       \n",
            "=================================================================\n",
            "Total params: 21,507\n",
            "Trainable params: 21,507\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7a3E7yE85Gd",
        "outputId": "3f927ce6-6753-4410-f74f-2eba5e040546"
      },
      "source": [
        "## Train\n",
        "model.fit(body_train, train_tags, epochs=25, batch_size=128, validation_split=0.1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "2316/2316 [==============================] - 5s 2ms/step - loss: 0.1841 - accuracy: 0.7468 - val_loss: 0.1176 - val_accuracy: 0.8323\n",
            "Epoch 2/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.1135 - accuracy: 0.8335 - val_loss: 0.1132 - val_accuracy: 0.8336\n",
            "Epoch 3/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.1099 - accuracy: 0.8360 - val_loss: 0.1117 - val_accuracy: 0.8312\n",
            "Epoch 4/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.1064 - accuracy: 0.8389 - val_loss: 0.1111 - val_accuracy: 0.8373\n",
            "Epoch 5/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.1054 - accuracy: 0.8398 - val_loss: 0.1108 - val_accuracy: 0.8336\n",
            "Epoch 6/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.1036 - accuracy: 0.8414 - val_loss: 0.1104 - val_accuracy: 0.8358\n",
            "Epoch 7/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.1031 - accuracy: 0.8433 - val_loss: 0.1111 - val_accuracy: 0.8354\n",
            "Epoch 8/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.1014 - accuracy: 0.8446 - val_loss: 0.1113 - val_accuracy: 0.8315\n",
            "Epoch 9/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.1016 - accuracy: 0.8448 - val_loss: 0.1109 - val_accuracy: 0.8334\n",
            "Epoch 10/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.1008 - accuracy: 0.8454 - val_loss: 0.1117 - val_accuracy: 0.8326\n",
            "Epoch 11/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.1000 - accuracy: 0.8471 - val_loss: 0.1115 - val_accuracy: 0.8386\n",
            "Epoch 12/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.0999 - accuracy: 0.8472 - val_loss: 0.1116 - val_accuracy: 0.8370\n",
            "Epoch 13/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.0997 - accuracy: 0.8464 - val_loss: 0.1117 - val_accuracy: 0.8322\n",
            "Epoch 14/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.0992 - accuracy: 0.8469 - val_loss: 0.1120 - val_accuracy: 0.8299\n",
            "Epoch 15/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.0987 - accuracy: 0.8484 - val_loss: 0.1130 - val_accuracy: 0.8297\n",
            "Epoch 16/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.0982 - accuracy: 0.8499 - val_loss: 0.1122 - val_accuracy: 0.8330\n",
            "Epoch 17/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.0982 - accuracy: 0.8492 - val_loss: 0.1129 - val_accuracy: 0.8310\n",
            "Epoch 18/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.0973 - accuracy: 0.8498 - val_loss: 0.1129 - val_accuracy: 0.8348\n",
            "Epoch 19/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.0980 - accuracy: 0.8496 - val_loss: 0.1130 - val_accuracy: 0.8316\n",
            "Epoch 20/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.0971 - accuracy: 0.8500 - val_loss: 0.1129 - val_accuracy: 0.8344\n",
            "Epoch 21/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.0971 - accuracy: 0.8507 - val_loss: 0.1135 - val_accuracy: 0.8332\n",
            "Epoch 22/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.0966 - accuracy: 0.8516 - val_loss: 0.1137 - val_accuracy: 0.8316\n",
            "Epoch 23/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.0965 - accuracy: 0.8513 - val_loss: 0.1134 - val_accuracy: 0.8325\n",
            "Epoch 24/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.0962 - accuracy: 0.8516 - val_loss: 0.1153 - val_accuracy: 0.8312\n",
            "Epoch 25/25\n",
            "2316/2316 [==============================] - 4s 2ms/step - loss: 0.0967 - accuracy: 0.8521 - val_loss: 0.1142 - val_accuracy: 0.8330\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe2e7bbce90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2kuQ9-a9YrD",
        "outputId": "e90d3956-049a-4c88-a64b-2326e89404e7"
      },
      "source": [
        "## Evalute\n",
        "model.evaluate(body_test, test_tags, batch_size=128)\n",
        "\n",
        "## Epochs = 3\n",
        "# 644/644 [==============================] - 1s 1ms/step - loss: 0.1101 - accuracy: 0.8389\n",
        "# [0.11007880419492722, 0.8388601541519165]\n",
        "\n",
        "##Epochs = 25\n",
        "# 644/644 [==============================] - 1s 1ms/step - loss: 0.1136 - accuracy: 0.8345\n",
        "# [0.1136125847697258, 0.8345237374305725]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "644/644 [==============================] - 1s 1ms/step - loss: 0.1116 - accuracy: 0.8378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11160676926374435, 0.8377547860145569]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi-1Cw95-CHt",
        "outputId": "40aef2b7-edaa-4e66-bc62-7c480f77c216"
      },
      "source": [
        "model.history.history"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "QKOBySElGx-C",
        "outputId": "cb6d1951-acea-4c2e-f0b9-34afc514a3af"
      },
      "source": [
        "losses.columns"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-40639fb87464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxZQTzqXGZk4"
      },
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wos_b7vMGsdA"
      },
      "source": [
        "model.save('keras_stackoverflow_tags.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TpWvQ82HlbU"
      },
      "source": [
        "%%writefile model_prediction1.py\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class CustomModelPrediction(object):\n",
        "\n",
        "    def __init__(self, model, processor):\n",
        "        self._model = model\n",
        "        self._processor = processor\n",
        "\n",
        "    def predict(self, instances, **kwargs):\n",
        "        preprocessed_data = self._processor.transform_text(instances)\n",
        "        predictions = self._model.predict(preprocessed_data)\n",
        "        return predictions.tolist()\n",
        "\n",
        "    @classmethod\n",
        "    def from_path(cls, model_dir):\n",
        "        import tensorflow.keras as keras\n",
        "        model = keras.models.load_model(\n",
        "            os.path.join(model_dir,'keras_stackoverflow_tags.h5')\n",
        "        )\n",
        "        with open(os.path.join(model_dir, 'processor_state.pkl'), 'rb') as f:\n",
        "            processor = pickle.load(f)\n",
        "\n",
        "        return cls(model, processor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c_rvh4jb51d"
      },
      "source": [
        "que3 = '''What I want to do: Turn a csv file into a list and copy each of those item and paste somewhere else.\n",
        "\n",
        "Why: Wanna a RPA script to do that for me.\n",
        "\n",
        "My problem: My csv file might have different count of rows. When I use pyperclip to copy an item, I can only copy using the index position, not a list. Need to copy each of those timecodes and paste, one by one, considering every possible list range.\n",
        "\n",
        "My lists Output:\n",
        "\n",
        "['00;00;00;00', '00;54;09;29']\n",
        "['00;54;09;28', '00;54;45;03']\n",
        "[nan, 'CRD']\n",
        "My code:\n",
        "\n",
        "decupagem = pd.read_csv('6353832.csv', encoding='UTF-16', sep='\\t')\n",
        "decupagem[['In','Out','Description']] \n",
        "\n",
        "\n",
        "tamanho_in = len(decupagem.In)\n",
        "tamanho_out = len(decupagem.Out)\n",
        "tamanho_comentario = len(decupagem.Description)\n",
        "\n",
        "#turning csv into list\n",
        "\n",
        "entrada = decupagem.In.tolist()[0:tamanho_out]\n",
        "print (entrada)\n",
        "\n",
        "saida = decupagem.Out.tolist()[0:tamanho_in]\n",
        "print(saida)\n",
        "\n",
        "comentario = decupagem.Description.tolist()[0:tamanho_comentario]\n",
        "print(comentario)\n",
        "\n",
        "for tc in entrada:\n",
        "    \n",
        "    pyperclip.copy(entrada[0:tamanho_in])\n",
        "    pyperclip.paste(entrada)\n",
        "Some help, please? Thanks!\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPkLcZ7yP3BF"
      },
      "source": [
        "#matplotlib\n",
        "que1 = 'i am getting error that figsize is not defined i dont know why is it so?'\n",
        "#keras\n",
        "que2 = \"Can I run dashdash model on gpu? \\nI'm running a dashdash model, with a submission deadline of 36 hours, if I train my model on the cpu it will take approx 50 hours, is there a way to run dashdash on gpu?\\nI'm using dashdash backend and running it on my Jupyter notebook, without anaconda installed.\"\n",
        "test_set = [que1, que2, que3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccsfkABmQzPH"
      },
      "source": [
        "from model_prediction1 import CustomModelPrediction\n",
        "\n",
        "classifier = CustomModelPrediction.from_path('.')\n",
        "results = classifier.predict(test_set)\n",
        "print(','.join(tag_encoder.classes_))\n",
        "for i in results:print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c9JiqpGY14b"
      },
      "source": [
        "for i in range(len(test_set)):\n",
        "    print('Predicted Labels:')\n",
        "    for idx, val in enumerate(results[i]):\n",
        "        if val > 0.7:\n",
        "            print(tag_encoder.classes_[idx])\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ9HMlRSRPsM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}